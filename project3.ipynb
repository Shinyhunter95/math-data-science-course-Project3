{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 3"
      ],
      "metadata": {
        "id": "0gdC70xxFyc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Fashion-MNIST image classification using sklearn"
      ],
      "metadata": {
        "id": "i9_7SnpMGKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(len(X_train), -1)\n",
        "X_test  = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "AB136H0PGKq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb21682-2d50-4cd5-81f3-4c881eb9e7a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(128, 64), #Number of hidden layers and neurons\n",
        "    activation='relu', #Activation functions\n",
        "    solver='adam', #Optimization method and the learning rate\n",
        "    alpha=0.001, #Regularization\n",
        "    early_stopping=True, validation_fraction=0.1, n_iter_no_change=10, #Early stopping\n",
        "    max_iter=50, #To pevent it from taking forever\n",
        "    random_state=1)\n",
        "\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "classification_report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix)\n",
        "\n"
      ],
      "metadata": {
        "id": "5GAsN-dmHjRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08fc5d88-f0e6-4a72-c497-873c62778d96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8853\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      1000\n",
            "           1       0.99      0.97      0.98      1000\n",
            "           2       0.79      0.81      0.80      1000\n",
            "           3       0.90      0.88      0.89      1000\n",
            "           4       0.80      0.83      0.82      1000\n",
            "           5       0.97      0.97      0.97      1000\n",
            "           6       0.71      0.67      0.69      1000\n",
            "           7       0.94      0.97      0.96      1000\n",
            "           8       0.97      0.96      0.97      1000\n",
            "           9       0.97      0.94      0.96      1000\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[842   2  22  19   5   1 103   0   6   0]\n",
            " [  3 971   2  18   3   0   2   0   1   0]\n",
            " [ 15   2 810  10  86   1  74   0   2   0]\n",
            " [ 25   5   9 884  49   0  24   0   4   0]\n",
            " [  0   0  81  20 832   0  66   0   1   0]\n",
            " [  0   0   0   1   0 968   0  15   3  13]\n",
            " [138   1  88  30  60   0 674   0   9   0]\n",
            " [  0   0   0   0   0  13   1 968   1  17]\n",
            " [  4   0  11   4   5   3   9   3 961   0]\n",
            " [  0   0   0   1   0  14   2  40   0 943]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Fashion-MNIST image classification  using pytorch"
      ],
      "metadata": {
        "id": "a2qcKggmIH8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# scale to [0,1], add channel dimension -> (N, 1, 28, 28)\n",
        "X_train = (X_train.astype(\"float32\") / 255.0)[:, None, :, :]\n",
        "X_test  = (X_test.astype(\"float32\")  / 255.0)[:,  None, :, :]\n",
        "\n",
        "y_train = y_train.astype(np.int64)\n",
        "y_test  = y_test.astype(np.int64)\n",
        "\n",
        "# train/val split: last 10k of train as validation\n",
        "X_tr, X_val = X_train[:50000], X_train[50000:]\n",
        "y_tr, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "# wrap in PyTorch TensorDatasets and DataLoaders\n",
        "train_ds = TensorDataset(torch.from_numpy(X_tr),  torch.from_numpy(y_tr))\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "B9IQwhgcIVOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b292786-7b8d-41d7-e8f2-b28a0c66f6cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm  # for progress bars\n",
        "\n",
        "# In colab, you should ``change runtime type'' to GPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# --- Define a simple fully connected network ---\n",
        "class FashionMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "model = FashionMLP().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# --- Training loop ---\n",
        "def train_model(model, train_loader, val_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * X.size(0)\n",
        "            correct += (outputs.argmax(1) == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "        train_loss = total_loss / total\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                outputs = model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "                val_loss += loss.item() * X.size(0)\n",
        "                val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "                val_total += y.size(0)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: \"\n",
        "              f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
        "              f\"Val loss={val_loss:.4f}, acc={val_acc:.4f}\")\n",
        "\n",
        "# --- Train ---\n",
        "train_model(model, train_loader, val_loader, epochs=10)\n",
        "\n",
        "# class FashionCNN(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "#         self.pool = nn.MaxPool2d(2, 2)\n",
        "#         self.dropout = nn.Dropout(0.25)\n",
        "#         self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
        "#         self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.conv1(x))\n",
        "#         x = self.pool(F.relu(self.conv2(x)))\n",
        "#         x = self.dropout(x)\n",
        "#         x = torch.flatten(x, 1)\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.fc2(x)\n",
        "#         return x\n",
        "# model = FashionCNN().to(device)\n",
        "\n",
        "# # --- Loss and optimizer ---\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# # --- Training loop ---\n",
        "# def train_model(model, train_loader, val_loader, epochs=10):\n",
        "#     for epoch in range(epochs):\n",
        "#         model.train()\n",
        "#         total_loss, correct, total = 0, 0, 0\n",
        "#         for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "#             X, y = X.to(device), y.to(device)\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(X)\n",
        "#             loss = criterion(outputs, y)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             total_loss += loss.item() * X.size(0)\n",
        "#             correct += (outputs.argmax(1) == y).sum().item()\n",
        "#             total += y.size(0)\n",
        "\n",
        "#         train_loss = total_loss / total\n",
        "#         train_acc = correct / total\n",
        "\n",
        "#         # --- Validation ---\n",
        "#         model.eval()\n",
        "#         val_loss, val_correct, val_total = 0, 0, 0\n",
        "#         with torch.no_grad():\n",
        "#             for X, y in val_loader:\n",
        "#                 X, y = X.to(device), y.to(device)\n",
        "#                 outputs = model(X)\n",
        "#                 loss = criterion(outputs, y)\n",
        "#                 val_loss += loss.item() * X.size(0)\n",
        "#                 val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "#                 val_total += y.size(0)\n",
        "\n",
        "#         val_loss /= val_total\n",
        "#         val_acc = val_correct / val_total\n",
        "\n",
        "#         print(f\"Epoch {epoch+1}: \"\n",
        "#               f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
        "#               f\"Val loss={val_loss:.4f}, acc={val_acc:.4f}\")\n",
        "\n",
        "# # --- Run training ---\n",
        "# train_model(model, train_loader, val_loader, epochs=10)\n",
        "\n",
        "# from torchvision import models, transforms\n",
        "# from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# # --- Step 1: Preprocessing ---\n",
        "# # Convert grayscale (1x28x28) → RGB (3x224x224)\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # grayscale → RGB\n",
        "# ])\n",
        "\n",
        "# class TransformedDataset(torch.utils.data.Dataset):\n",
        "#     def __init__(self, dataset, transform=None):\n",
        "#         self.dataset = dataset\n",
        "#         self.transform = transform\n",
        "#     def __len__(self):\n",
        "#         return len(self.dataset)\n",
        "#     def __getitem__(self, idx):\n",
        "#         x, y = self.dataset[idx]\n",
        "#         if self.transform:\n",
        "#             x = self.transform(x)\n",
        "#         return x, y\n",
        "\n",
        "# train_tf = TransformedDataset(train_ds, transform)\n",
        "# val_tf   = TransformedDataset(val_ds, transform)\n",
        "# test_tf  = TransformedDataset(test_ds, transform)\n",
        "\n",
        "# train_loader = DataLoader(train_tf, batch_size=64, shuffle=True)\n",
        "# val_loader   = DataLoader(val_tf, batch_size=128, shuffle=False)\n",
        "# test_loader  = DataLoader(test_tf, batch_size=128, shuffle=False)\n",
        "\n",
        "# # --- Step 2: Load pretrained model ---\n",
        "\n",
        "# model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# # --- Step 3: Modify classifier for 10 Fashion-MNIST classes ---\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False  # freeze all layers\n",
        "\n",
        "# num_features = model.fc.in_features\n",
        "# model.fc = nn.Sequential(\n",
        "#     nn.Linear(num_features, 256),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Dropout(0.4),\n",
        "#     nn.Linear(256, 10)\n",
        "# )\n",
        "\n",
        "# # --- Step 4: Fine-tune last layers ---\n",
        "# for param in model.fc.parameters():\n",
        "#     param.requires_grad = True  # unfreeze classifier\n",
        "\n",
        "# model = model.to(device)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
        "\n",
        "# # --- Step 5: Training loop ---\n",
        "# def train_model(model, train_loader, val_loader, epochs=5):\n",
        "#     for epoch in range(epochs):\n",
        "#         model.train()\n",
        "#         total_loss, correct, total = 0, 0, 0\n",
        "#         for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "#             X, y = X.to(device), y.to(device)\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(X)\n",
        "#             loss = criterion(outputs, y)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             total_loss += loss.item() * X.size(0)\n",
        "#             correct += (outputs.argmax(1) == y).sum().item()\n",
        "#             total += y.size(0)\n",
        "\n",
        "#         train_loss = total_loss / total\n",
        "#         train_acc = correct / total\n",
        "\n",
        "#         # Validation\n",
        "#         model.eval()\n",
        "#         val_loss, val_correct, val_total = 0, 0, 0\n",
        "#         with torch.no_grad():\n",
        "#             for X, y in val_loader:\n",
        "#                 X, y = X.to(device), y.to(device)\n",
        "#                 outputs = model(X)\n",
        "#                 loss = criterion(outputs, y)\n",
        "#                 val_loss += loss.item() * X.size(0)\n",
        "#                 val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "#                 val_total += y.size(0)\n",
        "\n",
        "#         val_loss /= val_total\n",
        "#         val_acc = val_correct / val_total\n",
        "\n",
        "#         print(f\"Epoch {epoch+1}: \"\n",
        "#               f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} | \"\n",
        "#               f\"Val loss={val_loss:.4f}, acc={val_acc:.4f}\")\n",
        "\n",
        "# train_model(model, train_loader, val_loader, epochs=5)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# --- Evaluate on test set ---\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            test_loss += loss.item() * X.size(0)\n",
        "            preds = outputs.argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "    test_loss /= total\n",
        "    test_acc = correct / total\n",
        "    print(f\"\\nTest loss: {test_loss:.4f}, accuracy: {test_acc:.4f}\")\n",
        "    return np.array(all_labels), np.array(all_preds)\n",
        "\n",
        "# --- Run test evaluation ---\n",
        "labels, preds = evaluate_model(model, test_loader)\n",
        "\n",
        "# --- Confusion matrix ---\n",
        "cm = confusion_matrix(labels, preds)\n",
        "class_names = [\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Fashion-MNIST Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# --- Classification report ---\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(labels, preds, target_names=class_names))"
      ],
      "metadata": {
        "id": "0REsDBunNmEl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "d1b72f4d-8120-408e-ce55-dc2cc75d5951"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:   0%|          | 0/782 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (64x150528 and 784x512)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3522914207.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# --- Train ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# class FashionCNN(nn.Module):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3522914207.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3522914207.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x150528 and 784x512)"
          ]
        }
      ]
    }
  ]
}